#!/usr/bin/env python3
"""å¢å¼ºçš„GPUç¯å¢ƒè¯Šæ–­è„šæœ¬"""

import sys
import json
sys.path.append('.')

from app.config import AiPlatformConfig
from app.services.ssh_manager import SSHManager

class GPUDiagnosticTool:
    """GPUè¯Šæ–­å·¥å…·"""
    
    def __init__(self):
        self.config = AiPlatformConfig()
        self.ssh_manager = SSHManager()
    
    def print_header(self):
        """æ‰“å°æ ‡é¢˜"""
        print("=" * 80)
        print("ğŸ” GPUç¯å¢ƒå¢å¼ºè¯Šæ–­å·¥å…·")
        print("=" * 80)
    
    def diagnose_server(self, server_name: str):
        """è¯Šæ–­æŒ‡å®šæœåŠ¡å™¨çš„GPUç¯å¢ƒ"""
        print(f"\nğŸ–¥ï¸  è¯Šæ–­æœåŠ¡å™¨: {server_name}")
        print("-" * 60)
        
        # æŸ¥æ‰¾æœåŠ¡å™¨é…ç½®
        server_config = None
        for server in self.config.gpu_servers:
            if server.name == server_name:
                server_config = server
                break
        
        if not server_config:
            print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°æœåŠ¡å™¨é…ç½® '{server_name}'")
            return False
        
        if not server_config.enabled:
            print(f"âš ï¸  è­¦å‘Š: æœåŠ¡å™¨ '{server_name}' å·²ç¦ç”¨")
            return False
        
        print(f"ğŸ“¡ æœåŠ¡å™¨åœ°å€: {server_config.host}:{server_config.port}")
        print(f"ğŸ‘¤ ç”¨æˆ·å: {server_config.username}")
        
        # åŸºç¡€è¿æ¥æµ‹è¯•
        if not self._test_ssh_connection(server_config):
            return False
        
        # GPUç¡¬ä»¶æ£€æµ‹
        self._check_gpu_hardware(server_config)
        
        # CUDAç¯å¢ƒæ£€æµ‹
        self._check_cuda_environment(server_config)
        
        # Pythonç¯å¢ƒæ£€æµ‹
        self._check_python_environments(server_config)
        
        # PyTorchç¯å¢ƒæ£€æµ‹
        self._check_pytorch_environments(server_config)
        
        # VLLMç¯å¢ƒæ£€æµ‹
        self._check_vllm_environment(server_config)
        
        return True
    
    def _test_ssh_connection(self, server_config):
        """æµ‹è¯•SSHè¿æ¥"""
        print("\nğŸ”— æµ‹è¯•SSHè¿æ¥...")
        
        exit_code, stdout, stderr = self.ssh_manager.execute_command(
            server_config, "echo 'SSHè¿æ¥æ­£å¸¸'", timeout=10
        )
        
        if exit_code == 0:
            print("âœ… SSHè¿æ¥æˆåŠŸ")
            return True
        else:
            print(f"âŒ SSHè¿æ¥å¤±è´¥")
            print(f"   é€€å‡ºç : {exit_code}")
            print(f"   é”™è¯¯ä¿¡æ¯: {stderr}")
            return False
    
    def _check_gpu_hardware(self, server_config):
        """æ£€æŸ¥GPUç¡¬ä»¶"""
        print("\nğŸ® æ£€æŸ¥GPUç¡¬ä»¶...")
        
        # æ£€æŸ¥nvidia-smi
        exit_code, stdout, stderr = self.ssh_manager.execute_command(
            server_config, "nvidia-smi", timeout=15
        )
        
        if exit_code == 0:
            print("âœ… nvidia-smi å¯ç”¨")
            
            # è·å–GPUè¯¦ç»†ä¿¡æ¯
            gpu_cmd = "nvidia-smi --query-gpu=index,name,driver_version,memory.total --format=csv,noheader"
            exit_code, gpu_info, _ = self.ssh_manager.execute_command(
                server_config, gpu_cmd, timeout=10
            )
            
            if exit_code == 0 and gpu_info.strip():
                print("ğŸ” GPUè®¾å¤‡ä¿¡æ¯:")
                for line in gpu_info.strip().split('\n'):
                    if line.strip():
                        print(f"   â€¢ {line.strip()}")
        else:
            print("âŒ nvidia-smi ä¸å¯ç”¨")
            print(f"   é”™è¯¯: {stderr}")
    
    def _check_cuda_environment(self, server_config):
        """æ£€æŸ¥CUDAç¯å¢ƒ"""
        print("\nğŸ”§ æ£€æŸ¥CUDAç¯å¢ƒ...")
        
        # æ£€æŸ¥CUDAç‰ˆæœ¬
        commands = [
            ("nvcc --version", "NVCCç¼–è¯‘å™¨"),
            ("cat /usr/local/cuda/version.txt 2>/dev/null || echo 'æ–‡ä»¶ä¸å­˜åœ¨'", "CUDAç‰ˆæœ¬æ–‡ä»¶"),
            ("ls -la /usr/local/cuda*/lib64/libcudart.so* 2>/dev/null || echo 'æœªæ‰¾åˆ°'", "CUDAè¿è¡Œæ—¶åº“"),
            ("echo $CUDA_HOME", "CUDA_HOMEç¯å¢ƒå˜é‡"),
            ("echo $LD_LIBRARY_PATH", "LD_LIBRARY_PATHç¯å¢ƒå˜é‡")
        ]
        
        for cmd, desc in commands:
            exit_code, stdout, stderr = self.ssh_manager.execute_command(
                server_config, cmd, timeout=10
            )
            
            print(f"  ğŸ“‹ {desc}:")
            if exit_code == 0:
                result = stdout.strip() if stdout.strip() else "(ç©ºè¾“å‡º)"
                print(f"     {result}")
            else:
                print(f"     âŒ æ‰§è¡Œå¤±è´¥: {stderr}")
    
    def _check_python_environments(self, server_config):
        """æ£€æŸ¥Pythonç¯å¢ƒ"""
        print("\nğŸ æ£€æŸ¥Pythonç¯å¢ƒ...")
        
        python_commands = [
            ("which python", "pythonè·¯å¾„"),
            ("which python3", "python3è·¯å¾„"),
            ("python --version", "pythonç‰ˆæœ¬"),
            ("python3 --version", "python3ç‰ˆæœ¬")
        ]
        
        for cmd, desc in python_commands:
            exit_code, stdout, stderr = self.ssh_manager.execute_command(
                server_config, cmd, timeout=10
            )
            
            print(f"  ğŸ“‹ {desc}:")
            if exit_code == 0:
                print(f"     âœ… {stdout.strip()}")
            else:
                print(f"     âŒ å¤±è´¥: {stderr}")
    
    def _check_pytorch_environments(self, server_config):
        """æ£€æŸ¥PyTorchç¯å¢ƒ"""
        print("\nğŸ”¥ æ£€æŸ¥PyTorchç¯å¢ƒ...")
        
        # æ£€æŸ¥ä¸åŒPythonç¯å¢ƒä¸­çš„PyTorch
        python_executables = ["python", "python3"]
        
        for python_exe in python_executables:
            print(f"\n  ğŸ” æ£€æŸ¥ {python_exe} ç¯å¢ƒ:")
            
            # æ£€æŸ¥PyTorchæ˜¯å¦å®‰è£…
            cmd = f"{python_exe} -c 'import torch; print(f\"PyTorchç‰ˆæœ¬: {{torch.__version__}}\")' 2>/dev/null"
            exit_code, stdout, stderr = self.ssh_manager.execute_command(
                server_config, cmd, timeout=15
            )
            
            if exit_code != 0:
                print(f"     âŒ PyTorchæœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥")
                continue
            
            print(f"     âœ… {stdout.strip()}")
            
            # æ£€æŸ¥CUDAæ”¯æŒ
            cuda_cmd = f"{python_exe} -c 'import torch; print(f\"CUDAå¯ç”¨: {{torch.cuda.is_available()}}\"); print(f\"CUDAç‰ˆæœ¬: {{torch.version.cuda}}\"); print(f\"GPUæ•°é‡: {{torch.cuda.device_count()}}\")' 2>/dev/null"
            exit_code, cuda_info, _ = self.ssh_manager.execute_command(
                server_config, cuda_cmd, timeout=15
            )
            
            if exit_code == 0:
                for line in cuda_info.strip().split('\n'):
                    if line.strip():
                        if "CUDAå¯ç”¨: True" in line:
                            print(f"     âœ… {line.strip()}")
                        elif "CUDAå¯ç”¨: False" in line:
                            print(f"     âŒ {line.strip()}")
                        else:
                            print(f"     ğŸ“‹ {line.strip()}")
            else:
                print(f"     âŒ CUDAæ£€æŸ¥å¤±è´¥")
            
            # æ£€æŸ¥PyTorchå®‰è£…ç»†èŠ‚
            detail_cmd = f"{python_exe} -c 'import torch; print(f\"ç¼–è¯‘æ ‡å¿—: {{torch.version.cuda}}\"); print(f\"æ„å»ºä¿¡æ¯: {{torch.__config__.show()}}\")' 2>/dev/null"
            exit_code, detail_info, _ = self.ssh_manager.execute_command(
                server_config, detail_cmd, timeout=15
            )
            
            if exit_code == 0 and detail_info.strip():
                print(f"     ğŸ“ è¯¦ç»†ä¿¡æ¯:")
                for line in detail_info.strip().split('\n')[:5]:  # åªæ˜¾ç¤ºå‰5è¡Œ
                    if line.strip():
                        print(f"        {line.strip()}")
    
    def _check_vllm_environment(self, server_config):
        """æ£€æŸ¥VLLMç¯å¢ƒ"""
        print("\nğŸš€ æ£€æŸ¥VLLMç¯å¢ƒ...")
        
        python_executables = ["python", "python3"]
        
        for python_exe in python_executables:
            print(f"\n  ğŸ” æ£€æŸ¥ {python_exe} ä¸­çš„VLLM:")
            
            # æ£€æŸ¥VLLMæ˜¯å¦å®‰è£…
            cmd = f"{python_exe} -c 'import vllm; print(f\"VLLMç‰ˆæœ¬: {{vllm.__version__}}\")' 2>/dev/null"
            exit_code, stdout, stderr = self.ssh_manager.execute_command(
                server_config, cmd, timeout=20
            )
            
            if exit_code == 0:
                print(f"     âœ… {stdout.strip()}")
                
                # æ£€æŸ¥VLLM GPUæ”¯æŒ
                gpu_cmd = f"{python_exe} -c 'from vllm import LLM; print(\"VLLM GPUæ”¯æŒæ­£å¸¸\")' 2>/dev/null"
                exit_code, gpu_result, _ = self.ssh_manager.execute_command(
                    server_config, gpu_cmd, timeout=30
                )
                
                if exit_code == 0:
                    print(f"     âœ… VLLM GPUæ”¯æŒæ­£å¸¸")
                else:
                    print(f"     âŒ VLLM GPUæ”¯æŒå¼‚å¸¸")
            else:
                print(f"     âŒ VLLMæœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥")
    
    def diagnose_all_servers(self):
        """è¯Šæ–­æ‰€æœ‰å¯ç”¨çš„æœåŠ¡å™¨"""
        self.print_header()
        
        enabled_servers = [s for s in self.config.gpu_servers if s.enabled]
        
        if not enabled_servers:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„GPUæœåŠ¡å™¨")
            return
        
        print(f"ğŸ“Š å‘ç° {len(enabled_servers)} ä¸ªå¯ç”¨çš„æœåŠ¡å™¨")
        
        for server in enabled_servers:
            success = self.diagnose_server(server.name)
            if not success:
                print(f"\nâŒ æœåŠ¡å™¨ {server.name} è¯Šæ–­å¤±è´¥")
        
        print("\n" + "=" * 80)
        print("ğŸ è¯Šæ–­å®Œæˆ")
        print("=" * 80)

def main():
    """ä¸»å‡½æ•°"""
    diagnostic_tool = GPUDiagnosticTool()
    
    if len(sys.argv) == 2:
        server_name = sys.argv[1]
        diagnostic_tool.print_header()
        diagnostic_tool.diagnose_server(server_name)
    else:
        diagnostic_tool.diagnose_all_servers()

if __name__ == "__main__":
    main() 